{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b838440a-377f-46f5-a47e-2772e76a20e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Final Project - Hydro Generation Raw\n",
    "#Kevin Carrion\n",
    "\n",
    "#Drop widgets\n",
    "# =========================\n",
    "dbutils.widgets.removeAll()\n",
    "\n",
    "# Databricks notebook source\n",
    "# =========================\n",
    "# Widgets\n",
    "# =========================\n",
    "dbutils.widgets.text(\"container\", \"raw\")\n",
    "dbutils.widgets.text(\"catalogo\", \"catalog_final_project\")\n",
    "dbutils.widgets.text(\"esquema\", \"bronze\")\n",
    "dbutils.widgets.text(\"datalake\", \"adlssdemoazure1201\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "container = dbutils.widgets.get(\"container\")\n",
    "catalogo  = dbutils.widgets.get(\"catalogo\")\n",
    "esquema   = dbutils.widgets.get(\"esquema\")\n",
    "datalake  = dbutils.widgets.get(\"datalake\")\n",
    "\n",
    "# Ruta en ADLS (DFS endpoint)\n",
    "ruta = f\"abfss://{container}@{datalake}.dfs.core.windows.net/hydro_generation_light.csv\"\n",
    "\n",
    "# Tabla destino en Bronze\n",
    "tabla_destino = f\"{catalogo}.{esquema}.hydro_generation_raw\"\n",
    "\n",
    "print(\"Ruta RAW:\", ruta)\n",
    "print(\"Tabla Bronze:\", tabla_destino)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# =========================\n",
    "# Schema\n",
    "# =========================\n",
    "gen_schema = StructType([\n",
    "    StructField(\"plant_id\", StringType(), True),\n",
    "    StructField(\"plant_name\", StringType(), True),\n",
    "    StructField(\"datetime\", StringType(), True),\n",
    "    StructField(\"installed_capacity_mw\", DoubleType(), True),\n",
    "    StructField(\"actual_generation_mw\", DoubleType(), True),\n",
    "    StructField(\"water_flow_m3s\", DoubleType(), True),\n",
    "    StructField(\"turbine_efficiency\", DoubleType(), True),\n",
    "    StructField(\"outage_flag\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(gen_schema)\n",
    "    .load(ruta)\n",
    "    .withColumn(\"_ingestion_ts\", F.current_timestamp())\n",
    "    .withColumn(\"_source_file\", F.input_file_name())\n",
    ")\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# =========================\n",
    "# Write Bronze (Delta Table)\n",
    "# =========================\n",
    "(\n",
    "    df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(tabla_destino)\n",
    ")\n",
    "\n",
    "print(f\"OK: {tabla_destino}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest_hydro_generation_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
